{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "symb.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0jgsHozyPwDir+nkqKk/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shirishbahirat/Artificial-Intelligence-1/blob/master/symb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEkRBXR3bNy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Basic pre-reqs:\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FORg9xWWbmo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install celluloid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoEExxqKbsEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export CUDA=cu101 && pip install --upgrade torch-scatter==latest+${CUDA} torch-sparse==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install --upgrade torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGwAIuEIb4Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/anon928374/gn/master/models.py -O models.py\n",
        "!wget https://raw.githubusercontent.com/anon928374/gn/master/simulate.py -O simulate.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAgJ3hbfcBfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import models\n",
        "import simulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1PKcgndcIaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.ones(1).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm3Z_d9mcOks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of simulations to run (it's fast, don't worry):\n",
        "ns = 10000\n",
        "# Potential (see below for options)\n",
        "sim = 'spring'\n",
        "# Number of nodes\n",
        "n = 4\n",
        "# Dimension\n",
        "dim = 2\n",
        "# Number of time steps\n",
        "nt = 1000\n",
        "\n",
        "\n",
        "#Standard simulation sets:\n",
        "n_set = [4, 8]\n",
        "sim_sets = [\n",
        " {'sim': 'r1', 'dt': [5e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'r2', 'dt': [1e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'spring', 'dt': [1e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'string', 'dt': [1e-2], 'nt': [1000], 'n': [30], 'dim': [2]},\n",
        " {'sim': 'charge', 'dt': [1e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'superposition', 'dt': [1e-3], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'damped', 'dt': [2e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        " {'sim': 'discontinuous', 'dt': [1e-2], 'nt': [1000], 'n': n_set, 'dim': [2, 3]},\n",
        "]\n",
        "\n",
        "\n",
        "#Select the hand-tuned dt value for a smooth simulation\n",
        "# (since scales are different in each potential):\n",
        "dt = [ss['dt'][0] for ss in sim_sets if ss['sim'] == sim][0]\n",
        "\n",
        "title = '{}_n={}_dim={}_nt={}_dt={}'.format(sim, n, dim, nt, dt)\n",
        "print('Running on', title)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2sU3gqScf37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simulate import SimulationDataset\n",
        "s = SimulationDataset(sim, n=n, dim=dim, nt=nt//2, dt=dt)\n",
        "# Update this to your own dataset, or regenerate:\n",
        "base_str = './'\n",
        "data_str = title\n",
        "s.simulate(ns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSO5wLhtcqx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = s.data\n",
        "s.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMUnWzPDcuPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.plot(0, animate=True, plot_size=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwa6JbuHczy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accel_data = s.get_acceleration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H58CF0YZc4HZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.from_numpy(np.concatenate([s.data[:, i] for i in range(0, s.data.shape[1], 5)]))\n",
        "y = torch.from_numpy(np.concatenate([accel_data[:, i] for i in range(0, s.data.shape[1], 5)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eEk0fhQc9Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMBqlFgXdAWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqevLmtbdGt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.nn import MetaLayer, MessagePassing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVRClUf1dLYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models import OGN, varOGN, make_packer, make_unpacker, get_edge_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o12W2cPJdRCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggr = 'add'\n",
        "hidden = 300\n",
        "\n",
        "test = '_l1_'\n",
        "\n",
        "#This test applies an explicit bottleneck:\n",
        "\n",
        "msg_dim = 100\n",
        "n_f = data.shape[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnITmZZodUvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.data import Data, DataLoader\n",
        "from models import get_edge_index\n",
        "edge_index = get_edge_index(n, sim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0pDfJRqdddZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if test == '_kl_':\n",
        "    ogn = varOGN(n_f, msg_dim, dim, dt=0.1, hidden=hidden, edge_index=get_edge_index(n, sim), aggr=aggr).cuda()\n",
        "else:\n",
        "    ogn = OGN(n_f, msg_dim, dim, dt=0.1, hidden=hidden, edge_index=get_edge_index(n, sim), aggr=aggr).cuda()\n",
        "\n",
        "messages_over_time = []\n",
        "ogn = ogn.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4IFJFoNdgz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_q = Data(\n",
        "    x=X_train[0].cuda(),\n",
        "    edge_index=edge_index.cuda(),\n",
        "    y=y_train[0].cuda())\n",
        "ogn(_q.x, _q.edge_index), ogn.just_derivative(_q).shape, _q.y.shape, ogn.loss(_q),"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBws5YBIdmkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = int(64 * (4 / n)**2)\n",
        "trainloader = DataLoader(\n",
        "    [Data(\n",
        "        Variable(X_train[i]),\n",
        "        edge_index=edge_index,\n",
        "        y=Variable(y_train[i])) for i in range(len(y_train))],\n",
        "    batch_size=batch,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "testloader = DataLoader(\n",
        "    [Data(\n",
        "        X_test[i],\n",
        "        edge_index=edge_index,\n",
        "        y=y_test[i]) for i in range(len(y_test))],\n",
        "    batch_size=1024,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFXUHZTNd6Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZrpPGMfd_an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_loss(self, g, augment=True, square=False):\n",
        "    if square:\n",
        "        return torch.sum((g.y - self.just_derivative(g, augment=augment))**2)\n",
        "    else:\n",
        "        base_loss = torch.sum(torch.abs(g.y - self.just_derivative(g, augment=augment)))\n",
        "        if test in ['_l1_', '_kl_']:\n",
        "            s1 = g.x[self.edge_index[0]]\n",
        "            s2 = g.x[self.edge_index[1]]\n",
        "            if test == '_l1_':\n",
        "                m12 = self.message(s1, s2)\n",
        "                regularization = 1e-2\n",
        "                #Want one loss value per row of g.y:\n",
        "                normalized_l05 = torch.sum(torch.abs(m12))\n",
        "                return base_loss, regularization * batch * normalized_l05 / n**2 * n\n",
        "            elif test == '_kl_':\n",
        "                regularization = 1\n",
        "                #Want one loss value per row of g.y:\n",
        "                tmp = torch.cat([s1, s2], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
        "                raw_msg = self.msg_fnc(tmp)\n",
        "                mu = raw_msg[:, 0::2]\n",
        "                logvar = raw_msg[:, 1::2]\n",
        "                full_kl = torch.sum(torch.exp(logvar) + mu**2 - logvar)/2.0\n",
        "                return base_loss, regularization * batch * full_kl / n**2 * n\n",
        "        return base_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gRiYLhCeBUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_lr = 1e-3\n",
        "\n",
        "opt = torch.optim.Adam(ogn.parameters(), lr=init_lr, weight_decay=1e-8)\n",
        "\n",
        "# total_epochs = 200\n",
        "total_epochs = 30\n",
        "\n",
        "\n",
        "batch_per_epoch = int(1000*10 / (batch/32.0))\n",
        "\n",
        "sched = OneCycleLR(opt, max_lr=init_lr,\n",
        "                   steps_per_epoch=batch_per_epoch,#len(trainloader),\n",
        "                   epochs=total_epochs, final_div_factor=1e5)\n",
        "\n",
        "batch_per_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F9NO2PfeN81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 0\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHYKu2i4eUCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as onp\n",
        "onp.random.seed(0)\n",
        "test_idxes = onp.random.randint(0, len(X_test), 1000)\n",
        "\n",
        "#Record messages over test dataset here:\n",
        "newtestloader = DataLoader(\n",
        "    [Data(\n",
        "        X_test[i],\n",
        "        edge_index=edge_index,\n",
        "        y=y_test[i]) for i in test_idxes],\n",
        "    batch_size=len(X_test),\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVe9JJdeeZF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as onp\n",
        "import pandas as pd\n",
        "\n",
        "def get_messages(ogn):\n",
        "\n",
        "    def get_message_info(tmp):\n",
        "        ogn.cpu()\n",
        "\n",
        "        s1 = tmp.x[tmp.edge_index[0]]\n",
        "        s2 = tmp.x[tmp.edge_index[1]]\n",
        "        tmp = torch.cat([s1, s2], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
        "        if test == '_kl_':\n",
        "            raw_msg = ogn.msg_fnc(tmp)\n",
        "            mu = raw_msg[:, 0::2]\n",
        "            logvar = raw_msg[:, 1::2]\n",
        "\n",
        "            m12 = mu\n",
        "        else:\n",
        "            m12 = ogn.msg_fnc(tmp)\n",
        "\n",
        "        all_messages = torch.cat((\n",
        "            s1,\n",
        "            s2,\n",
        "            m12), dim=1)\n",
        "        if dim == 2:\n",
        "            columns = [elem%(k) for k in range(1, 3) for elem in 'x%d y%d vx%d vy%d q%d m%d'.split(' ')]\n",
        "            columns += ['e%d'%(k,) for k in range(msg_dim)]\n",
        "        elif dim == 3:\n",
        "            columns = [elem%(k) for k in range(1, 3) for elem in 'x%d y%d z%d vx%d vy%d vz%d q%d m%d'.split(' ')]\n",
        "            columns += ['e%d'%(k,) for k in range(msg_dim)]\n",
        "\n",
        "\n",
        "        return pd.DataFrame(\n",
        "            data=all_messages.cpu().detach().numpy(),\n",
        "            columns=columns\n",
        "        )\n",
        "\n",
        "    msg_info = []\n",
        "    for i, g in enumerate(newtestloader):\n",
        "        msg_info.append(get_message_info(g))\n",
        "\n",
        "    msg_info = pd.concat(msg_info)\n",
        "    msg_info['dx'] = msg_info.x1 - msg_info.x2\n",
        "    msg_info['dy'] = msg_info.y1 - msg_info.y2\n",
        "    if dim == 2:\n",
        "        msg_info['r'] = np.sqrt(\n",
        "            (msg_info.dx)**2 + (msg_info.dy)**2\n",
        "        )\n",
        "    elif dim == 3:\n",
        "        msg_info['dz'] = msg_info.z1 - msg_info.z2\n",
        "        msg_info['r'] = np.sqrt(\n",
        "            (msg_info.dx)**2 + (msg_info.dy)**2 + (msg_info.dz)**2\n",
        "        )\n",
        "    \n",
        "    return msg_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1jjU90esNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recorded_models = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA0GgubHevuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in tqdm(range(epoch, total_epochs)):\n",
        "    ogn.cuda()\n",
        "    total_loss = 0.0\n",
        "    i = 0\n",
        "    num_items = 0\n",
        "    while i < batch_per_epoch:\n",
        "        for ginput in trainloader:\n",
        "            if i >= batch_per_epoch:\n",
        "                break\n",
        "            opt.zero_grad()\n",
        "            ginput.x = ginput.x.cuda()\n",
        "            ginput.y = ginput.y.cuda()\n",
        "            ginput.edge_index = ginput.edge_index.cuda()\n",
        "            ginput.batch = ginput.batch.cuda()\n",
        "            if test in ['_l1_', '_kl_']:\n",
        "                loss, reg = new_loss(ogn, ginput, square=False)\n",
        "                ((loss + reg)/int(ginput.batch[-1]+1)).backward()\n",
        "            else:\n",
        "                loss = ogn.loss(ginput, square=False)\n",
        "                (loss/int(ginput.batch[-1]+1)).backward()\n",
        "            opt.step()\n",
        "            sched.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            i += 1\n",
        "            num_items += int(ginput.batch[-1]+1)\n",
        "\n",
        "    cur_loss = total_loss/num_items\n",
        "    print(cur_loss)\n",
        "    cur_msgs = get_messages(ogn)\n",
        "    cur_msgs['epoch'] = epoch\n",
        "    cur_msgs['loss'] = cur_loss\n",
        "    messages_over_time.append(cur_msgs)\n",
        "    \n",
        "    ogn.cpu()\n",
        "    from copy import deepcopy as copy\n",
        "    recorded_models.append(ogn.state_dict())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QazxkqDbgb8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UajNYU9RghIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from celluloid import Camera\n",
        "from copy import deepcopy as copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kvBGEqwgiky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_force_components = True\n",
        "plot_sparsity = False\n",
        "plot_rotation = False\n",
        "if plot_force_components:\n",
        "    fig, ax = plt.subplots(1, dim, figsize=(4*dim, 4))\n",
        "if plot_sparsity or plot_rotation:\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "cam = Camera(fig)\n",
        "\n",
        "\n",
        "last_alpha_x1 = 0.0\n",
        "last_alpha_y1 = 0.0\n",
        "t = lambda _: _#tqdm\n",
        "for i in t(range(0, len(messages_over_time), 1)):\n",
        "    msgs = copy(messages_over_time[i])\n",
        "\n",
        "    msgs['bd'] = msgs.r + 1e-2\n",
        "\n",
        "    try:\n",
        "        msg_columns = ['e%d'%(k) for k in range(1, msg_dim+1)]\n",
        "        msg_array = np.array(msgs[msg_columns])\n",
        "    except:\n",
        "        msg_columns = ['e%d'%(k) for k in range(msg_dim)]\n",
        "        msg_array = np.array(msgs[msg_columns])\n",
        "\n",
        "    msg_importance = msg_array.std(axis=0)\n",
        "    most_important = np.argsort(msg_importance)[-dim:]\n",
        "    msgs_to_compare = msg_array[:, most_important]\n",
        "    msgs_to_compare = (msgs_to_compare - np.average(msgs_to_compare, axis=0)) / np.std(msgs_to_compare, axis=0)\n",
        "\n",
        "    if plot_sparsity:\n",
        "        ax.pcolormesh(msg_importance[np.argsort(msg_importance)[::-1][None, :15]], cmap='gray_r', edgecolors='k')\n",
        "        # plt.colorbar()\n",
        "        plt.axis('off')\n",
        "        plt.grid(True)\n",
        "        ax.set_aspect('equal')\n",
        "        plt.text(15.5, 0.5, '...', fontsize=30)\n",
        "        # fig.suptitle(title + test + 'mse=%.3e'%(min_result.fun/len(msgs),))\n",
        "        plt.tight_layout()\n",
        "    \n",
        "    if plot_force_components or plot_rotation:\n",
        "        pos_cols = ['dx', 'dy']\n",
        "        if dim == 3:\n",
        "            pos_cols.append('dz')\n",
        "\n",
        "        if sim != 'spring':\n",
        "            raise NotImplementedError(\"The current force function is for a spring. You will need to change the force function below to that expected by your simulation.\")\n",
        "        force_fnc = lambda msg: -(msg.bd - 1)[:, None] * np.array(msg[pos_cols]) / msg.bd[:, None]\n",
        "\n",
        "        expected_forces = force_fnc(msgs)\n",
        "\n",
        "        def percentile_sum(x):\n",
        "            x = x.ravel()\n",
        "            bot = x.min()\n",
        "            top = np.percentile(x, 90)\n",
        "            msk = (x>=bot) & (x<=top)\n",
        "            frac_good = (msk).sum()/len(x)\n",
        "            return x[msk].sum()/frac_good\n",
        "\n",
        "        from scipy.optimize import minimize\n",
        "\n",
        "        def linear_transformation_2d(alpha):\n",
        "\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1]) + alpha[2]\n",
        "            lincomb2 = (alpha[3] * expected_forces[:, 0] + alpha[4] * expected_forces[:, 1]) + alpha[5]\n",
        "\n",
        "            score = (\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 0] - lincomb1)) +\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 1] - lincomb2))\n",
        "            )/2.0\n",
        "\n",
        "            return score\n",
        "\n",
        "        def out_linear_transformation_2d(alpha):\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1]) + alpha[2]\n",
        "            lincomb2 = (alpha[3] * expected_forces[:, 0] + alpha[4] * expected_forces[:, 1]) + alpha[5]\n",
        "\n",
        "            return lincomb1, lincomb2\n",
        "\n",
        "        def linear_transformation_3d(alpha):\n",
        "\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1] + alpha[2] * expected_forces[:, 2]) + alpha[3]\n",
        "            lincomb2 = (alpha[0+4] * expected_forces[:, 0] + alpha[1+4] * expected_forces[:, 1] + alpha[2+4] * expected_forces[:, 2]) + alpha[3+4]\n",
        "            lincomb3 = (alpha[0+8] * expected_forces[:, 0] + alpha[1+8] * expected_forces[:, 1] + alpha[2+8] * expected_forces[:, 2]) + alpha[3+8]\n",
        "\n",
        "            score = (\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 0] - lincomb1)) +\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 1] - lincomb2)) +\n",
        "                percentile_sum(np.square(msgs_to_compare[:, 2] - lincomb3))\n",
        "            )/3.0\n",
        "\n",
        "            return score\n",
        "\n",
        "        def out_linear_transformation_3d(alpha):\n",
        "\n",
        "            lincomb1 = (alpha[0] * expected_forces[:, 0] + alpha[1] * expected_forces[:, 1] + alpha[2] * expected_forces[:, 2]) + alpha[3]\n",
        "            lincomb2 = (alpha[0+4] * expected_forces[:, 0] + alpha[1+4] * expected_forces[:, 1] + alpha[2+4] * expected_forces[:, 2]) + alpha[3+4]\n",
        "            lincomb3 = (alpha[0+8] * expected_forces[:, 0] + alpha[1+8] * expected_forces[:, 1] + alpha[2+8] * expected_forces[:, 2]) + alpha[3+8]\n",
        "\n",
        "            return lincomb1, lincomb2, lincomb3\n",
        "\n",
        "        if dim == 2:\n",
        "            min_result = minimize(linear_transformation_2d, np.ones(dim**2 + dim), method='Powell')\n",
        "        if dim == 3:\n",
        "            min_result = minimize(linear_transformation_3d, np.ones(dim**2 + dim), method='Powell')\n",
        "        print(title, test, 'gets', min_result.fun/len(msgs))\n",
        "\n",
        "        if plot_rotation:\n",
        "            q = min_result.x\n",
        "            alphax1, alphay1, offset1 = q[:3]\n",
        "            alphax2, alphay2, offset2 = q[3:]\n",
        "            \n",
        "            s1 = alphax1**2 + alphay1**2\n",
        "            s2 = alphax2**2 + alphay2**2\n",
        "            \n",
        "            if (\n",
        "                    (alphax2 - last_alpha_x1)**2\n",
        "                    + (alphay2 - last_alpha_y1)**2  <\n",
        "                   (alphax1 - last_alpha_x1)**2\n",
        "                    + (alphay1 - last_alpha_y1)**2):\n",
        "                \n",
        "                alphax1, alphay1, offset1 = q[3:]\n",
        "                alphax2, alphay2, offset2 = q[:3]\n",
        "                \n",
        "            last_alpha_x1 = alphax1\n",
        "            last_alpha_y1 = alphay1\n",
        "            s1 = alphax1**2 + alphay1**2\n",
        "            s2 = alphax2**2 + alphay2**2\n",
        "            alphax1 /= s1**0.5 * 2\n",
        "            alphay1 /= s1**0.5 * 2\n",
        "            alphax2 /= s2**0.5 * 2\n",
        "            alphay2 /= s2**0.5 * 2\n",
        "            \n",
        "            ax.arrow(0.5, 0.5, alphax1, alphay1, color='k', head_width=0.05, length_includes_head=True)\n",
        "            ax.arrow(0.5, 0.5, alphax2, alphay2, color='k', head_width=0.05, length_includes_head=True)\n",
        "            ax.axis('off')\n",
        "        \n",
        "        if plot_force_components:\n",
        "            for i in range(dim):\n",
        "                if dim == 3:\n",
        "                    px = out_linear_transformation_3d(min_result.x)[i]\n",
        "                else:\n",
        "                    px = out_linear_transformation_2d(min_result.x)[i]\n",
        "\n",
        "                py = msgs_to_compare[:, i]\n",
        "                ax[i].scatter(px, py,\n",
        "                              alpha=0.1, s=0.1, color='k')\n",
        "                ax[i].set_xlabel('Linear combination of forces')\n",
        "                ax[i].set_ylabel('Message Element %d'%(i+1))\n",
        "\n",
        "                xlim = np.array([np.percentile(px, q) for q in [10, 90]])\n",
        "                ylim = np.array([np.percentile(py, q) for q in [10, 90]])\n",
        "                xlim[0], xlim[1] = xlim[0] - (xlim[1] - xlim[0])*0.05, xlim[1] + (xlim[1] - xlim[0])*0.05\n",
        "                ylim[0], ylim[1] = ylim[0] - (ylim[1] - ylim[0])*0.05, ylim[1] + (ylim[1] - ylim[0])*0.05\n",
        "\n",
        "                ax[i].set_xlim(xlim)\n",
        "                ax[i].set_ylim(ylim)\n",
        "                \n",
        "        plt.tight_layout()\n",
        "    \n",
        "    cam.snap()\n",
        "\n",
        "ani = cam.animate()\n",
        "    \n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHZ_tZoIg2P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simulate import make_transparent_color"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxVXPMRIg7q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.integrate import odeint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dndAd3M8hC3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "camera = Camera(fig)\n",
        "\n",
        "for current_model in [-1] + [1, 34, 67, 100, 133, 166, 199]:\n",
        "    i = 4 #Use this simulation\n",
        "    if current_model > len(recorded_models):\n",
        "        continue\n",
        "\n",
        "    #Truth:\n",
        "    cutoff_time = 300\n",
        "    times = onp.array(s.times)[:cutoff_time]\n",
        "    x_times = onp.array(data[i, :cutoff_time])\n",
        "    masses = x_times[:, :, -1]\n",
        "    length_of_tail = 75\n",
        "\n",
        "    #Learned:\n",
        "    e = edge_index.cuda()\n",
        "    ogn.cpu()\n",
        "    if current_model > -1:\n",
        "        ogn.load_state_dict(recorded_models[current_model])\n",
        "    else:\n",
        "        # Random model!\n",
        "        ogn = OGN(n_f, msg_dim, dim, dt=0.1, hidden=hidden, edge_index=get_edge_index(n, sim), aggr=aggr).cuda()\n",
        "    ogn.cuda()\n",
        "    \n",
        "    def odefunc(y, t=None):\n",
        "        y = y.reshape(4, 6).astype(np.float32)\n",
        "        cur = Data(\n",
        "            x=torch.from_numpy(y).cuda(),\n",
        "            edge_index=e\n",
        "        )\n",
        "        dx = y[:, 2:4]\n",
        "        dv = ogn.just_derivative(cur).cpu().detach().numpy()\n",
        "        dother = np.zeros_like(dx)\n",
        "        return np.concatenate((dx, dv, dother), axis=1).ravel()\n",
        "\n",
        "    datai = odeint(odefunc, (onp.asarray(x_times[0]).ravel()), times).reshape(-1, 4, 6)\n",
        "    x_times2 = onp.array(datai)\n",
        "\n",
        "    d_idx = 10\n",
        "    for t_idx in range(d_idx, cutoff_time, d_idx):\n",
        "        start = max([0, t_idx-length_of_tail])\n",
        "        ctimes = times[start:t_idx]\n",
        "        cx_times = x_times[start:t_idx]\n",
        "        cx_times2 = x_times2[start:t_idx]\n",
        "        for j in range(n):\n",
        "            rgba = make_transparent_color(len(ctimes), j/n)\n",
        "            ax[0].scatter(cx_times[:, j, 0], cx_times[:, j, 1], color=rgba)\n",
        "            ax[1].scatter(cx_times2[:, j, 0], cx_times2[:, j, 1], color=rgba)\n",
        "            black_rgba = rgba\n",
        "            black_rgba[:, :3] = 0.75\n",
        "            ax[1].scatter(cx_times[:, j, 0], cx_times[:, j, 1], color=black_rgba, zorder=-1)\n",
        "\n",
        "        for k in range(2):\n",
        "            ax[k].set_xlim(-1, 3)\n",
        "            ax[k].set_ylim(-3, 1)\n",
        "        plt.tight_layout()\n",
        "        camera.snap()\n",
        "\n",
        "# camera.animate().save('multiple_animations_with_comparison.mp4')\n",
        "from IPython.display import HTML\n",
        "HTML(camera.animate().to_jshtml())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-J8PsI2hPPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_message = np.argmax([np.std(messages_over_time[-1]['e%d'%(i,)]) for i in range(100)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr6s8-URhZSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages_over_time[-1][['e%d'%(best_message,), 'dx', 'dy', 'r', 'm1', 'm2']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}